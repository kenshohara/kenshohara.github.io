<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <script src="https://use.typekit.net/hdw5tos.js"></script>
  <script>try{Typekit.load({ async: true });}catch(e){}</script>
  <title>Kensho Hara | AIST</title>
  <link rel="stylesheet" href="normalize.css">
  <link rel="stylesheet" href="page.css">
  <script src="./js/smooth-scroll.js"></script>
</head>

<body class="common">
  <a href="http://kenshohara.github.io/index.html">
    <img src="https://ga-beacon.appspot.com/UA-97463075-3/kenshohara.github.io/index.html?pixel" />
  </a>

  <header>
    <nav>
      <ul class="navi" data-scroll-header>
        <li><a href="#" data-scroll class="navi--item">Top</a></li>
        <li><a href="#profile" data-scroll class="navi--item">Profile</a></li>
        <!-- <li><a href="#research" data-scroll class="navi--item">Research</a></li> -->
        <li><a href="#publications" data-scroll class="navi--item">Publications</a></li>
        <li><a href="./index_jp.html" class="navi--item">Japanese</a></li>
      </ul>
    </nav>
  </header>
  <main>
    <article class="image-desc">
      <img class="image-desc--img" src="./hara.jpg" alt="Kensho Hara"/>
      <section class="image-desc-txt">
        <h1 class="<image-desc--heading">Kensho Hara</h1>
        <p>
          Researcher <br />
          National Institute of <br />
          Advanced Industrial Science and Technology, <br />
          Computer Vision Research Team, <br />
          Artificial Intelligence Research Center, <br />
        </p>
        <p>
          E-mail: kensho.hara [at] aist.go.jp <br />
          TEL: 029-861-5094
        </p>
      </section>
    </article>
    <!-- <article class="info">
      <h1 class="info--heading" id="news">News</h1>
      <section>
        <li>
          (Sep. 9, 2018) Our paper is presented at ECCV 2018 Workshop.
        </li>
        <li>
          (Aug. 23, 2018) Our paper is presented at ICPR 2018.
        </li>
        <li>
          (Feb. 21, 2018) <a href="https://arxiv.org/pdf/1711.09577.pdf">Our paper</a> is accepted to CVPR 2018.
          <a href="https://github.com/kenshohara/3D-ResNets-PyTorch">The codes and pretrained models</a> are available.
        </li>
        <li>
          (Oct. 4, 2017) Our paper is accepted to IEICE Transactions on Information and Systems.
        </li>
        <li>
          (Aug. 25, 2017) <a href="https://github.com/kenshohara/3D-ResNets">Our codes and pretrained models</a> of ICCV Workshop paper are available.
        </li>
        <li>
          (Aug. 22, 2017) <a href="https://arxiv.org/abs/1708.07632">Our paper</a> is accepted to ICCV 2017 Workshop.
        </li>
        <li>
          (Aug. 15, 2017) Our paper is accepted to ACMMM 2017 Workshop.
        </li>
      </section>
    </article> -->
    <article class="info">
      <h1 class="info--heading" id="profile">Profile</h1>
      <section>
        <h2 class="info--heading2">Education</h2>
        <p class="info--txt">
          Bachelor's degree in Engineering, Nagoya University, 2012 <br />
          Master's degree in Information Science, Nagoya University, 2014 <br />
          Ph.D. degree in Information Science, Nagoya University, 2017 <br />
        </p>
      </section>
    </article>
    <!-- <article class="info">
      <h1 class="info--heading" id="research">Research</h1>
      <section>
        <h2 class="info--heading2">Research Projects</h2>
        <p class="info--txt">
          Human action recognition and detection in videos <br />
          (Under construction...)
        </p>
      </section>
    </article> -->
    <article class="info">
      <h1 class="info--heading" id="publications">Publications</h1>
      <section>
        <h2 class="info--heading2">Journal Papers</h2>
        <ol class="info--txt info--txt__list">
          <li class="info--txt info--txt__list_elem">
            Xueting Wang, <a class="info--txt__weight_500">Kensho Hara</a>, Yu Enokibori, Takatsugu Hirayama, Kenji Mase, <br />
            <a class="info--txt__weight_700">"Personal Viewpoint Navigation based on Object Trajectory Distribution for Multi-view Videos"</a>, <br />
            IEICE Transactions on Information and Systems, Vol. E101-D, No. 1, pp. 193–204, 2018.
          </li>
          <li class="info--txt info--txt__list_elem">
            <a class="info--txt__weight_500">Kensho Hara</a>, Takatsugu Hirayama, Kenji Mase, <br />
            <a class="info--txt__weight_700">"Vote Distribution Model for Hough-based Action Detection"</a>, <br />
            IEICE Transactions on Information and Systems, Vol. E99-D, No. 11, pp. 2796–2808, 2016.
          </li>
          <li class="info--txt info--txt__list_elem">
            <a class="info--txt__weight_500">Kensho Hara</a>, Takatsugu Hirayama, Kenji Mase,<br />
            <a class="info--txt__weight_700">"Simultaneous Recognition of Human Action and its Location Estimation Based on Multi-view Hough Voting"</a>， <br />
            IEEJ Transactions on Electronics, Information and Systems, Vol. 134, No. 5, pp. 634–642, 2014. (IN JAPANESE)
          </li>
        </ol>
      </section>
      <section>
        <h2 class="info--heading2">International Conference</h2>
        <ol class="info--txt info--txt__list">
          <li class="info--txt info--txt__list_elem">
            <a class="info--txt__weight_500">Kensho Hara</a>, Hirokatsu Kataoka, Yutaka Satoh, <br />
            <a class="info--txt__weight_700">"Towards Good Practice for Action Recognition with Spatiotemporal 3D Convolutions"</a>, <br />
            International Conference on Pattern Recognition (ICPR), 2018. <br />
            <a href="https://arxiv.org/pdf/1711.09577.pdf" class="info--txt__weight_700">arxiv</a>,
            <a href="https://github.com/kenshohara/3D-ResNets" class="info--txt__weight_700">GitHub</a> (codes and pretrained models)
          </li>
          <li class="info--txt info--txt__list_elem">
            <a class="info--txt__weight_500">Kensho Hara</a>, Hirokatsu Kataoka, Yutaka Satoh, <br />
            <a class="info--txt__weight_700">"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?"</a>, <br />
            IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018. <br />
            <a href="https://arxiv.org/pdf/1711.09577.pdf" class="info--txt__weight_700">arxiv</a>,
            <a href="https://github.com/kenshohara/3D-ResNets" class="info--txt__weight_700">GitHub</a> (codes and pretrained models)
          </li>
          <li class="info--txt info--txt__list_elem">
            <a class="info--txt__weight_500">Kensho Hara</a>, Hirokatsu Kataoka, Yutaka Satoh, <br />
            <a class="info--txt__weight_700">"Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition"</a>, <br />
            ICCV Workshop on Action, Gesture, and Emotion Recognition, 2017. <br />
            <a href="http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w44/Hara_Learning_Spatio-Temporal_Features_ICCV_2017_paper.pdf" class="info--txt__weight_700">paper</a>,
            <a href="https://github.com/kenshohara/3D-ResNets" class="info--txt__weight_700">GitHub</a> (codes and pretrained models)
          </li>
          <li class="info--txt info--txt__list_elem">
            Xueting Wang, Yu Enokibori, Takatsugu Hirayama, <a class="info--txt__weight_500">Kensho Hara</a>, Kenji Mase, <br />
            <a class="info--txt__weight_700">"User Group based Viewpoint Recommendation using User Attributes for Multiview Videos"</a>, <br />
            ACM MM Workshop on Multimodal Understanding of Social, Affective and Subjective Attributes (MUSA), 2017.
          </li>
          <li class="info--txt info--txt__list_elem">
            Xueting Wang, <a class="info--txt__weight_500">Kensho Hara</a>, Yu Enokibori, Takatsugu Hirayama, Kenji Mase, <br />
            <a class="info--txt__weight_700">"Personal Multi-view Viewpoint Recommendation based on Trajectory Distribution of the Viewing Target"</a>, <br />
            ACM Multimedia Conference (ACMMM), 2016.
          </li>
          <li class="info--txt info--txt__list_elem">
            <a class="info--txt__weight_500">Kensho Hara</a>, Kenji Mase, <br />
            <a class="info--txt__weight_700">"Hough-based Action Detection with Time-warped Voting"</a>, <br />
            The 3rd Asian Conference on Pattern Recognition (ACPR), 2015.
          </li>
          <li class="info--txt info--txt__list_elem">
            <a class="info--txt__weight_500">Kensho Hara</a>, Takatsugu Hirayama, Kenji Mase, <br />
            <a class="info--txt__weight_700">"Trend-Sensitive Hough Forests for Action Detection"</a>, <br />
            International Conference on Image Processing (ICIP), 2014.
          </li>
          <li class="info--txt info--txt__list_elem">
            <a class="info--txt__weight_500">Kensho Hara</a>, Takatsugu Hirayama, Kenji Mase, <br />
            <a class="info--txt__weight_700">"Simultaneous Action Recognition and Localization Based on Multi-View Hough Voting"</a>, <br />
            The 2nd Asian Conference on Pattern Recognition (ACPR), 2013.
          </li class="info--txt info--txt__list_elem">
        </ol>
      </section>
    </article>
  </main>
  <footer class="footer">
    © 2015 Kensho Hara
  </footer>
  <script>
	  smoothScroll.init({
      selector: '[data-scroll]', // Selector for links (must be a valid CSS selector)
      selectorHeader: '[data-scroll-header]', // Selector for fixed headers (must be a valid CSS selector)
      speed: 500, // Integer. How fast to complete the scroll in milliseconds
      easing: 'easeInOutCubic', // Easing pattern to use
      updateURL: true, // Boolean. Whether or not to update the URL with the anchor hash on scroll
      offset: 0, // Integer. How far to offset the scrolling anchor location in pixels
      callback: function ( toggle, anchor ) {} // Function to run after scrolling
    });
  </script>
</body>
</html>
